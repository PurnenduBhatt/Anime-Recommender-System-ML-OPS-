# Updated Logstash Pipeline Configuration 
# Save this to ./logstash/pipeline/logstash.conf
input {
  beats {
    port => 5044
    client_inactivity_timeout => 300
  }
  file {
    path => "/logs/ml-app.log"
    start_position => "beginning"
    sincedb_path => "/dev/null"
    stat_interval => "1s"
    discover_interval => "5s"
    type => "python-logs"
  }
}

filter {
  # Add fingerprint for unique document IDs
  fingerprint {
    source => ["message"]
    target => "[@metadata][fingerprint]"
    method => "MD5"
  }
  
  # Handle logs from Flask app's internal Filebeat
  if [agent][type] == "filebeat" {
    # The logs are already parsed by Filebeat inside the container
    # Just ensure timestamp is set properly
    if [asctime] {
      date {
        match => [ "asctime", "ISO8601" ]
        target => "@timestamp"
      }
    }
  }
  
  # Handle logs picked up directly by Logstash file input
  if [type] == "python-logs" {
    # Try to parse JSON if available
    if [message] =~ "^\s*[\{\[]" {
      json {
        source => "message"
        skip_on_invalid_json => true
        tag_on_failure => ["_json_parse_failure"]
      }
    }
    
    # Parse HTTP logs if present
    if [message] =~ "HTTP" {
      grok {
        match => { "message" => "(?<client_ip>%{IP}|-)\s+-\s+-\s+\[%{NOTSPACE:request_date}\]\s+\"%{WORD:http_method}\s+%{NOTSPACE:request_path}\s+HTTP/%{NUMBER:http_version}\"\s+%{NUMBER:response_code}\s+%{NUMBER:response_size}" }
        tag_on_failure => ["_http_parse_failure"]
      }
    }
    
    # Set timestamp from asctime if available
    if [asctime] {
      date {
        match => [ "asctime", "ISO8601" ]
        target => "@timestamp"
      }
    }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "frontend-logs-%{+YYYY.MM.dd}"
    document_id => "%{[@metadata][fingerprint]}"
  }
  
  # Output events to stdout for debugging
  stdout {
    codec => rubydebug
  }
}