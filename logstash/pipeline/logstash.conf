# Updated Logstash Pipeline Configuration
# Save this content to ./logstash/pipeline/logstash.conf

input {
  beats {
    port => 5044
  }
  file {
    path => "/logs/ml-app.log"
    start_position => "beginning"
    sincedb_path => "/dev/null"
    type => "python-logs"
  }
}

filter {
  # Add fingerprint for unique document IDs
  fingerprint {
    source => ["message"]
    target => "[@metadata][fingerprint]"
    method => "MD5"
  }
  
  if [type] == "python-logs" {
    # Remove JSON filter since Filebeat is already parsing JSON
    
    # Parse HTTP request info from log message if available
    if [message] =~ "HTTP" {
      grok {
        match => { "message" => "(?<client_ip>%{IP}|-)\s+-\s+-\s+\[%{NOTSPACE:request_date}\]\s+\"%{WORD:http_method}\s+%{NOTSPACE:request_path}\s+HTTP/%{NUMBER:http_version}\"\s+%{NUMBER:response_code}\s+%{NUMBER:response_size}" }
        tag_on_failure => ["_http_parse_failure"]
      }
    }
    
    # Set timestamp from the log entry
    date {
      match => [ "asctime", "ISO8601" ]
      target => "@timestamp"
    }
  }
}

output {
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "frontend-logs-%{+YYYY.MM.dd}"
    document_id => "%{[@metadata][fingerprint]}"
  }
  stdout {
    codec => rubydebug
  }
}